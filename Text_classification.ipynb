{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "Text classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0V__KYJdHK22"
      },
      "source": [
        "# Text Classification\n",
        "\n",
        "## \"*Words. I know words. I have the best words!*\"\n",
        "*- Noam Chomsky*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nz_9qaHMHK24"
      },
      "source": [
        "# Overview\n",
        "\n",
        "To train an NLP model to classify text, we need:\n",
        "1. a way to preprocess text\n",
        "2. a label for each text\n",
        "3. a way to represent each text as vector input\n",
        "4. a model to learn  a function $f(input) = label$\n",
        "5. a way to evaluate how well the model works\n",
        "6. a way to predict new data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUZsmiucHK25"
      },
      "source": [
        "# Checklist: how to classify my data\n",
        "\n",
        "1. label at ***least 2000*** instances in your data set\n",
        "2. preprocess the text of *all* instances in your data (labeled and unlabeled)\n",
        "3. read in the labeled instances and their labels\n",
        "4. use `TfidfVectorizer` to extract the features and transform them into feature vectors\n",
        "5. select the top $N$ features (where $N$ is smaller than the number of labeled instances)\n",
        "6. use 5-fold CV to find the best regularization parameter, top $N$ feature selection, and maybe feature generation and preprocessing steps\n",
        "7. create a classifier with the best settings\n",
        "\n",
        "Once you are satisfied with the results:\n",
        "\n",
        "8. read in the rest of the (unlabeled) instances\n",
        "9. use the `TfidfVectorizer` from 4. to transform the new data into vectors\n",
        "10. use the `SelectKBest` selector from 5. to get the top $N$ features\n",
        "11. use the classifier from 7. to predict the labels for the new data\n",
        "12. save the predicted labels or probabilities to your database or an Excel file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXDp4JI3HK26"
      },
      "source": [
        "# The Data\n",
        "\n",
        "We'll use a subset of a Kaggle data set of wine reviews. For speed reasons, we will focus on descriptions of wines from France, Italy, Spain, and the US. The text data has already been preprocessed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yr__zBRtH9Hx"
      },
      "source": [
        "%%capture\n",
        "!wget http://www.dirkhovy.com/portfolio/papers/download/wine_reviews_classification.xlsx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KON9JFisHK27"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = pd.read_excel('wine_reviews_classification.xlsx')\n",
        "print(len(data))\n",
        "\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5PenA3PzHK29"
      },
      "source": [
        "Classifying new (**held-out**) data is called **prediction**. We reuse the weights we have learned before on a new data matrix to predict the new outcomes.\n",
        "\n",
        "Important: the new data needs to have the same number of features, and undergo the same preprocessing! The best way to ensure this is to make data splits just after the processing, before we do anything else.\n",
        "\n",
        "We will work with a random subset of 20000 instances, but you could use the whole data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMpOG5d-HK29"
      },
      "source": [
        "# determine the size of training, develpment and test set:\n",
        "N = len(data)\n",
        "train_size = int(N*0.5)\n",
        "dev_size = int(N*0.25)\n",
        "test_size = int(N*0.25)\n",
        "\n",
        "# split the data into training, develpment and test set:\n",
        "train = data[:train_size]\n",
        "dev = data[train_size: train_size+dev_size]\n",
        "test = data[train_size+dev_size:]\n",
        "print(len(train), len(dev), len(test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_cHB3kUHK2-"
      },
      "source": [
        "Instead of manually splitting the data, you can also use `sklearn`'s built-in `StratifiedKFold` or `StratifiedShuffleSplit`, which ensures equal proportions of labels in all splits."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7oof6j2nHK2_"
      },
      "source": [
        "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vyAZljc6HK3A"
      },
      "source": [
        "# The Labels\n",
        "\n",
        "We'll predict the country of origin (Italy, US, France, or Spain) here, but we could potentially choose any other column."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQSwnRanHK3A"
      },
      "source": [
        "target = 'country'\n",
        "\n",
        "y_train = train[target]\n",
        "\n",
        "print(y_train[:10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--OSpAkhHK3B"
      },
      "source": [
        "# select dev and test from the same label column\n",
        "y_dev = dev[target]\n",
        "y_test = test[target]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zp1FKH5GHK3B"
      },
      "source": [
        "You can get the classes (and their mapping to an intger) from the fitted classifier."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29tt-4gYHK3C"
      },
      "source": [
        "Let's look at the label distributions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gq24elFPHK3C"
      },
      "source": [
        "from collections import Counter\n",
        "{k: v/len(y_train) for k, v in Counter(y_train).items()}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFmTGb1mHK3D"
      },
      "source": [
        "{k: v/len(y_dev) for k, v in Counter(y_dev).items()}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqP8vKN2HK3D"
      },
      "source": [
        "{k: v/len(y_test) for k, v in Counter(y_test).items()}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efJ5DwdoHK3D"
      },
      "source": [
        "# Transforming the Input\n",
        "\n",
        "## Bags of words\n",
        "\n",
        "The easiest way is to represent features is as a counts of all words in the text. It takes two steps:\n",
        "1. collect the counts for each word\n",
        "2. transform the individual counts into one big matrix\n",
        "\n",
        "The result is a matrix $X$ with one row for each instance, and one column for each word in the vocabulary.\n",
        "\n",
        "![Bag of words procedure](bow.png)\n",
        "\n",
        "We can use the `TfidfVectorizer` object to get the frequency of each word, weighted by the number of documents it occurs in (that tempers the influence of freuqent, but uninformative words):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TfPunQHHK3D"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer(ngram_range=(1,2), \n",
        "                             min_df=0.001, \n",
        "                             max_df=0.7, \n",
        "                             analyzer='word',\n",
        "                             sublinear_tf=True\n",
        "                            )\n",
        "\n",
        "X_train = vectorizer.fit_transform(train['description_cleaned'])\n",
        "print(X_train.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6VPMFC_PHK3F"
      },
      "source": [
        "X_dev = vectorizer.transform(dev['description_cleaned'])\n",
        "X_test = vectorizer.transform(test['description_cleaned'])\n",
        "print(X_dev.shape, X_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZxVFp810HK3G"
      },
      "source": [
        "# Dummy Baseline\n",
        "\n",
        "So, is that performance good? Let's compare to a **baseline**, i.e., a null-hypothesis. The simplest one is that all instances belong to the most frequent class in the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmPNskfEHK3G"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from sklearn.dummy import DummyClassifier\n",
        "\n",
        "# find the most frequent class in the training data\n",
        "most_frequent = DummyClassifier(strategy='most_frequent')\n",
        "most_frequent.fit(X_train, y_train)\n",
        "\n",
        "# get the performance on the development set\n",
        "dumb_predictions = most_frequent.predict(X_dev)\n",
        "\n",
        "print(classification_report(y_dev, dumb_predictions))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7Eqhp5jHK3H"
      },
      "source": [
        "Obviously, that's not very good. Which is actually good news, since it means we have a fair chance of doing better with a smarter classifier."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LwydhLuIHK3I"
      },
      "source": [
        "# A Classifier\n",
        "\n",
        "Let's use a simple Logistic Regression classifier. Technically, it is a Ridge classifier, because it is Logistic Regression with L2 regularization (see below), but we need not worry about that now.\n",
        "\n",
        "Let's fit a model, parallelizing it to speed up the process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYGtBfYCHK3I"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "classifier = LogisticRegression(n_jobs=-1, multi_class='auto', solver='lbfgs')\n",
        "%time classifier.fit(X_train, y_train)\n",
        "print(classifier)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4SQu70MHK3I"
      },
      "source": [
        "To get the classes and their order/integer ID, you can use the `classes_` property of the fitted classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91LwnNxVHK3J"
      },
      "source": [
        "classifier.classes_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBvZPONQHK3J"
      },
      "source": [
        "Let's get the performance of this classifier on the development set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vz9XXdbvHK3J"
      },
      "source": [
        "predictions = classifier.predict(X_dev)\n",
        "print(predictions[:10])\n",
        "print(classification_report(y_dev,predictions))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4D41AHTHK3J"
      },
      "source": [
        "Instead, we can also predict the probabilities of belonging to each class. Here, we get  a distribution over classes, i.e., each column is the probability of one class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxoS9C2KHK3J"
      },
      "source": [
        "probabilities = classifier.predict_proba(X_dev)\n",
        "\n",
        "prob_distro_df = pd.DataFrame(data=probabilities, columns=classifier.classes_)\n",
        "\n",
        "prob_distro_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2ZidHzYHK3J"
      },
      "source": [
        "The `predict()` function uses a threshold of $0.5$ to assign binary labels, or the argmax for multiple classes. If you want to emphasize precision more, you can base the label on a higher threshold. If you want to emphasize recall, you can base the label on a lower threshold."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fcOq5UIfHK3K"
      },
      "source": [
        "# Getting better\n",
        "\n",
        "If we do not like the results, there are several parameters we can experiment with:\n",
        "1. class balance\n",
        "2. regularization\n",
        "3. feature selection\n",
        "4. dimensionality reduction\n",
        "5. different classifiers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLasEApAHK3K"
      },
      "source": [
        "## 1. Class balance\n",
        "\n",
        "We can weigh each class inversely proportional to its frequency, i.e., assign higher weight to rarer classes, to improve performance on them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Zcpd2MJHK3K"
      },
      "source": [
        "classifier_balanced = LogisticRegression(n_jobs=-1, \n",
        "                                         multi_class='auto', \n",
        "                                         solver='lbfgs', \n",
        "                                         class_weight='balanced' # added\n",
        "                                         \n",
        "                                        )\n",
        "%time classifier_balanced.fit(X_train, y_train)\n",
        "predictions_balanced = classifier_balanced.predict(X_dev)\n",
        "\n",
        "print(classification_report(y_dev, predictions_balanced))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3LdVuPOHK3L"
      },
      "source": [
        "## 2. Regularization strength\n",
        "Typically, performance is lower on unseen data, because our model **overfit** the training data: it expects the new data to look *exactly* the same as the training data. That is almost never true.\n",
        "\n",
        "In order to prevent the model from overfitting, we need to **regularize** it. Essentially, we make it harder to learn the training data.\n",
        "\n",
        "It makes sense to force the model to spread the weights more evenly over all features, rather than bet on a few feature, which mighht not be present in future data.\n",
        "\n",
        "We can do this by training the model with the `C` parameter of the L2 regularization. The default is `1`. Lower values mean stricter regularization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "cWCJ7DLIHK3L"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "best_c = None\n",
        "best_performance = 0.0\n",
        "\n",
        "for c in [50, 20, 10, 5, 2, 0.5, 0.1, 0.05, 0.01]:\n",
        "    print(c)\n",
        "    classifier_c = LogisticRegression(n_jobs=-1, \n",
        "                                      multi_class='auto', \n",
        "                                      solver='lbfgs',\n",
        "                                      class_weight='balanced',\n",
        "                                      C=c\n",
        "                                     )\n",
        "    \n",
        "    classifier_c.fit(X_train, y_train)\n",
        "    predictions_c = classifier_c.predict(X_dev)\n",
        "    score = f1_score(y_dev, predictions_c, average='micro')\n",
        "    if score > best_performance:\n",
        "        best_performance = score\n",
        "        best_c = c\n",
        "        print(\"New best performance: {}\".format(score))\n",
        "        \n",
        "    print(classification_report(y_dev, predictions_c))\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDo8zAXPHK3L"
      },
      "source": [
        "Instead of a manual search, we can also use a grid search over all classifier parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBuNRByrHK3L"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "\n",
        "# setting up the classifier we want to optimize\n",
        "base_clf = LogisticRegression(n_jobs=-1)\n",
        "\n",
        "# defining parameters to optimize\n",
        "param_grid = {'C': [20, 10, 5, 1, 0.01],\n",
        "              'class_weight': ['balanced', None]\n",
        "             }\n",
        "# run the optimization\n",
        "search = GridSearchCV(base_clf, # use the classifier defined above\n",
        "                      param_grid, # use the parameters defined above\n",
        "                      cv=5, # use 5-fold cross validation\n",
        "                      scoring='f1_micro') # use micro F1 to select best model\n",
        "search.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TITyroaHK3N"
      },
      "source": [
        "Let's look at the winning combination of parameters: we access the `best_estimator_` property of the grid search object."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsg3MXzLHK3N"
      },
      "source": [
        "clf_best = search.best_estimator_\n",
        "print(clf_best.get_params(), search.best_score_)\n",
        "\n",
        "# fit this classifier on the entire training data, instead of CV\n",
        "clf_best.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FuI65uPbHK3N"
      },
      "source": [
        "## 3. Feature selection\n",
        "\n",
        "Not all features are helpful. Let's select the top $k$ based on how well they predict they outcome of the training data.\n",
        "\n",
        "We use two libraries from `sklearn`, `SelectKBest` (the selection algorithm) and `chi2` (the selection criterion)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3kI0AnOHK3N"
      },
      "source": [
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# set up the sequence of steps\n",
        "pipe = Pipeline([\n",
        "    ('selector', 'passthrough'), # feature selection\n",
        "    ('classifier', clf_best) # the classifier\n",
        "])\n",
        "\n",
        "# specify selection range\n",
        "param_grid = [\n",
        "    {\n",
        "        'selector': [SelectKBest(chi2)],\n",
        "        'selector__k': [4500, 4000, 2000, 1000, 500]\n",
        "    },\n",
        "]\n",
        "\n",
        "# fit the model to different feature sets\n",
        "grid = GridSearchCV(pipe, \n",
        "                    param_grid=param_grid, \n",
        "                    cv=5, \n",
        "                    scoring='f1_micro',\n",
        "                    n_jobs=-1,\n",
        "                   )\n",
        "grid.fit(X_train, y_train)\n",
        "print(grid.best_score_, grid.best_params_['selector'])\n",
        "\n",
        "# save the best selector\n",
        "selector = grid.best_params_['selector'].fit(X_train, y_train)\n",
        "\n",
        "# transform the data matrices of train, dev, and test to the new dimensionality\n",
        "X_train_sel = selector.transform(X_train)\n",
        "X_dev_sel = selector.transform(X_dev)\n",
        "X_test_sel = selector.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PTVE7HlHK3O"
      },
      "source": [
        "classifier_sel = LogisticRegression(n_jobs=-1, multi_class='auto', solver='lbfgs', \n",
        "                                    class_weight='balanced')\n",
        "classifier_sel.fit(X_train_sel, y_train)\n",
        "\n",
        "predictions_sel = classifier_sel.predict(X_dev_sel)\n",
        "print(classification_report(y_dev, predictions_sel))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0tCs-YPHK3O"
      },
      "source": [
        "## 4. Dimensionality reduction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FcLog-v2HK3O"
      },
      "source": [
        "from sklearn.decomposition import TruncatedSVD\n",
        "\n",
        "# set up the sequence of steps\n",
        "pipe = Pipeline([\n",
        "    ('reduction', 'passthrough'),\n",
        "    ('classifier', clf_best)\n",
        "])\n",
        "\n",
        "# specify selection range\n",
        "param_grid = [\n",
        "    {\n",
        "        'reduction': [TruncatedSVD()],\n",
        "        'reduction__n_components': [400, 300, 200, 100]\n",
        "    },\n",
        "]\n",
        "\n",
        "# fit the model to different feature sets\n",
        "grid = GridSearchCV(pipe, \n",
        "                    param_grid=param_grid, \n",
        "                    cv=5, \n",
        "                    scoring='f1_micro',\n",
        "                    n_jobs=-1,\n",
        "                   )\n",
        "grid.fit(X_train, y_train)\n",
        "print(grid.best_score_, grid.best_params_['reduction'])\n",
        "\n",
        "# save the best selector\n",
        "reductor = grid.best_params_['reduction'].fit(X_train, y_train)\n",
        "X_train_red = reductor.transform(X_train)\n",
        "X_dev_red = reductor.transform(X_dev)\n",
        "X_test_red = reductor.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fICJDdLyHK3O"
      },
      "source": [
        "# Getting insights\n",
        "\n",
        "The fitted model has coefficients (weights, betas) for each word/feature in our vocabulary.\n",
        "\n",
        "To find out which features are most indicative for each class, we need some code to map back from the coefficient to the corresponding feature.\n",
        "\n",
        "If we reduced the number of features, we need to take that into account."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cc_uENxHK3P"
      },
      "source": [
        "# get the names of the features\n",
        "features = vectorizer.get_feature_names()\n",
        "num_feats = len(features)\n",
        "reduced_size = classifier_sel.coef_.shape[1]\n",
        "\n",
        "# get the indices of the selection\n",
        "top_scores = selector.scores_.argsort()[-num_feats:]\n",
        "\n",
        "# sort feature names\n",
        "best_indicator_terms = [features[i] for i in sorted(top_scores)] \n",
        "\n",
        "# get class with highest weight for each feature\n",
        "top_class = [classifier_sel.classes_[c] for c in classifier_sel.coef_.argmax(axis=0)]\n",
        "\n",
        "# make DataFrame\n",
        "top_indicator_scores = pd.DataFrame(data={'feature': best_indicator_terms[:reduced_size], \n",
        "                                          'class': top_class[:reduced_size],\n",
        "                                          'coefficient': classifier_sel.coef_.max(axis=0)})\n",
        "\n",
        "# sort in descending order\n",
        "top_indicator_scores.sort_values('coefficient', ascending=False, inplace=True)\n",
        "top_indicator_scores.tail(20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FUhaPKCHK3Q"
      },
      "source": [
        "# Significance Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_k61NCBHK3Q"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score\n",
        "\n",
        "def bootstrap_sample(system1, system2, gold, samples=1000, score=f1_score, average='micro'):\n",
        "    \"\"\"\n",
        "    compute the proportion of times the performance difference of the \n",
        "    two systems on a subsample is significantly different from the \n",
        "    performance on the entire sample\n",
        "    \"\"\"\n",
        "    N = len(gold) # number of instances\n",
        "    \n",
        "    # make sure the two systems have the same number of samples\n",
        "    assert len(system1) == N and len(system2) == N, 'samples have different lengths'\n",
        "\n",
        "    # compute performance score on entire sample\n",
        "    base_score1 = score(gold, system1, average=average)\n",
        "    base_score2 = score(gold, system2, average=average)\n",
        "    print(\"Base difference: {} vs. {}\".format(base_score1, base_score2))\n",
        "\n",
        "    # switch systems if system2 is better\n",
        "    if base_score2 > base_score1:\n",
        "        system1, system2 = system2, system1\n",
        "        base_score1, base_score2 = base_score2, base_score1\n",
        "    \n",
        "    # compute the difference\n",
        "    basedelta = base_score1 - base_score2\n",
        "    assert basedelta > 0, 'Wrong system first, system1 needs to be better!'\n",
        "\n",
        "    system1 = np.array(system1)\n",
        "    system2 = np.array(system2)\n",
        "    gold = np.array(gold)\n",
        "\n",
        "    p = 0\n",
        "    deltas = []\n",
        "    for i in range(samples):\n",
        "        # select a subsample, with replacement\n",
        "        sample = np.random.choice(N, size=N, replace=True)\n",
        "\n",
        "        # collect data corresponding to subsample\n",
        "        sample1 = system1[sample]\n",
        "        sample2 = system2[sample]\n",
        "        gold_sample = gold[sample]\n",
        "\n",
        "        # compute scores on subsample\n",
        "        sample_score1 = score(gold_sample, sample1, average=average)\n",
        "        sample_score2 = score(gold_sample, sample2, average=average)\n",
        "        sample_delta = sample_score1 - sample_score2\n",
        "\n",
        "        # check whether the observed sample difference is at least \n",
        "        # twice as large as the base difference\n",
        "        if sample_delta > 2*basedelta:\n",
        "            p += 1\n",
        "        deltas.append(sample_delta)\n",
        "                \n",
        "    return p/samples, deltas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFNrw9Y5HK3R"
      },
      "source": [
        "p_value, deltas = bootstrap_sample(predictions, dumb_predictions, y_dev)\n",
        "print(p_value, p_value < 0.01)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xrx4FaOyHK3R"
      },
      "source": [
        "%matplotlib inline\n",
        "import pandas as pd\n",
        "pd.Series(deltas).plot.hist(bins=20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KU-uo41FHK3R"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}