{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "knitr::opts_chunk$set(echo = TRUE)\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 0. Nameščanje programov (Packages)\n",
                "\n",
                "Namestitev: Če ste program(e) že namestili, lahko preskočite ta korak.\n",
                "\n",
                "Znak \\# v programskem bloku (chunk) pomeni, da se ta vrstica ne izvaja. Odstrani\n",
                "\\# če želite program namestiti.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# # Programe, ki jih še nimate, lahko namestite tudi na ta način (odstranite #):\n",
                "# install.packages(\"readtext\")\n",
                "# install.packages(\"quanteda\")\n",
                "# install.packages(\"quanteda.textstats\")\n",
                "# install.packages(\"quanteda.textplots\")\n",
                "# install.packages(\"tidyverse\")\n",
                "# install.packages(\"wordcloud2\")\n",
                "# install.packages(\"tidytext\")\n",
                "# install.packages(\"udpipe\")\n",
                "# install.packages(\"janitor\")\n",
                "# install.packages(\"scales\")\n",
                "# install.packages(\"widyr\")\n",
                "# install.packages(\"syuzhet\")\n",
                "# install.packages(\"corpustools\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 0. Programi\n",
                "\n",
                "Najprej moramo zagnati programe, ki jih potrebujemo za načrtovano delo.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "library(readtext)\n",
                "library(quanteda)\n",
                "library(quanteda.textstats)\n",
                "library(quanteda.textplots)\n",
                "library(tidyverse)\n",
                "library(tidytext)\n",
                "library(wordcloud2)\n",
                "library(udpipe)\n",
                "library(janitor)\n",
                "library(scales)\n",
                "library(widyr)\n",
                "library(syuzhet)\n",
                "library(corpustools)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 1. Preberemo besedila\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "txt = readtext(\"data/books/*.txt\", encoding = \"UTF-8\")\n",
                "txt\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Alternativno lahko besedila preberemo tudi z medmrežja:\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "txt1 = readtext(\"https://raw.githubusercontent.com/tpetric7/tpetric7.github.io/main/data/books/prozess.txt\", encoding = \"UTF-8\")\n",
                "txt2 = readtext(\"https://raw.githubusercontent.com/tpetric7/tpetric7.github.io/main/data/books/tom.txt\", encoding = \"UTF-8\")\n",
                "\n",
                "# Datoteki združimo\n",
                "txt = rbind(txt1,txt2)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 2. Ustvarimo korpus\n",
                "\n",
                "Ustvarimo korpus ali jezikovno gradivo. Ukaz v programu \"quanteda\" je corpus().\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "romane = corpus(txt)\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Povzetek:\n",
                "\n",
                "Program quanteda ima dve funkciji za povzemanje: - summary() -\n",
                "textstat_summary()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "(romanstatistik = textstat_summary(romane)\n",
                ")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "povzetek = summary(romane)\n",
                "povzetek\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Podatke iz povzetka bi lahko uporabili npr. za izračun povprečne dolžine povedi\n",
                "v besedilih:\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "povzetek %>% \n",
                "  group_by(Text) %>%\n",
                "  mutate(dolzina_povedi = Tokens/Sentences)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Lahko bi tudi izračunali kazalnik slovarske raznolikosti v besedilih, tj.\n",
                "razmerje med različnimi (types) in pojavnicami (tokens), kar se angleščini\n",
                "imenuje \"type token ratio\" (ttr).\n",
                "\n",
                "Razlikujemo med slovarskimi enotami (lemma), različnicami (types) in pojavnicami\n",
                "(tokens):\n",
                "\n",
                "npr. nemški glagol \"gehen\" je slovarska enota, ki ima več različnic ali oblik\n",
                "(npr. gehe, gehst, geht, gehen, geht, ging, gingst, ... gegangen).\n",
                "\n",
                "Pojavnice: nekatere oblike glagola so pogostejše kot druge, nekatere pa se v\n",
                "izbranem besedilu ne pojavljajo.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "povzetek %>% \n",
                "  group_by(Text) %>% \n",
                "  mutate(ttr = Types/Tokens)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Program quanteda ima za ugotavljanje slovarske raznolikosti (lexical diversity)\n",
                "več možnosti, kar zahteva razcepitev besedil na manjše enote, tj. tokens\n",
                "(besede, ločila idr.). Za nekatere funkcije moramo ustvariti besedilno matriko\n",
                "(document frequency matrix, dfm).\n",
                "\n",
                "# 3. Tokenizacija\n",
                "\n",
                "Če želimo več izvedeti o besedilih, npr. katere besede se pojavljajo v\n",
                "besedilih, moramo najprej ustvariti seznam besedilnih enot (tj. besed, ločil\n",
                "idr.).\n",
                "\n",
                "Iz gradiva izvlečemo besedne oblike (npr. s pomočjo presledkov).\n",
                "\n",
                "Za tokenizacijo ima quanteda ukaz tokens().\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "besede = tokens(romane)\n",
                "head(besede)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 4. Čiščenje\n",
                "\n",
                "S seznama lahko izločimo \"nebesede\":\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "besede = tokens(romane, remove_punct = T, remove_symbols = T, remove_numbers = T, remove_url = T)\n",
                "head(besede)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Izločimo lahko tudi besede, ki za vsebinsko analizo niso zaželene (\"stopwords\").\n",
                "\n",
                "V izbranih besedilih motijo tudi angleške besede, ki niso sestavni del nemških\n",
                "besedil.\n",
                "\n",
                "concatenate = združi: c()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "stoplist_de = c(stopwords(\"de\"), \"dass\", \"Aligned\", \"by\", \"autoalignment\", \"Source\", \"Project\", \n",
                "                \"bilingual-texts.com\", \"fully\", \"reviewed\")\n",
                "besede = tokens_select(besede, pattern = stoplist_de, selection = \"remove\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Naslednji seznam bomo uporabljali za ustvarjanje konkordance, tj. seznama\n",
                "sobesedil, v katerem se nahaja iskalni niz (npr. neka beseda).\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "stoplist_en = c(\"Aligned\", \"by\", \"autoalignment\", \"Source\", \"Project\", \n",
                "                \"bilingual-texts.com\", \"fully\", \"reviewed\")\n",
                "\n",
                "# Obdržali bomo ločila\n",
                "woerter = tokens(romane, remove_symbols = T, remove_numbers = T, remove_url = T)\n",
                "# Odstranili bomo angleške besede na začetku besedil\n",
                "woerter = tokens_select(woerter, pattern = stoplist_en, selection = \"remove\", padding = TRUE)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 5. Kwic\n",
                "\n",
                "Za sestavo konkordanc ima program quanteda funkcijo *kwic()* (keyword in\n",
                "context).\n",
                "\n",
                "Možno je iskati posamezne besede, besedne zveze, uporabljamo pa lahko tudi\n",
                "nadomestne znake (npr. \\*).\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "kwic(woerter, pattern = c(\"Frau\", \"Herr\"))\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Konkordanco bomo pretvorili v podatkovno zbirko, tj. *data.frame* ali\n",
                "*tibble()*. Prednost je npr., da tako pridobimo imena stolpcev (tj.\n",
                "spremenljivk).\n",
                "\n",
                "*kwic()* ima več možnosti, npr. \"case_insensitive = FALSE\" razlikuje med\n",
                "velikimi in malimi črkami. Privzeta vrednost je \"TRUE\", tj. da tega ne razlikuje\n",
                "(tako kot Excel).\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "(konkordanca = kwic(woerter, pattern = c(\"Frau\", \"Herr\"), case_insensitive = FALSE) %>% \n",
                "  as_tibble()\n",
                ")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Z ukazom *count()* lahko preštejemo, koliko pojavnic je KWIC našel.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "konkordanca %>% \n",
                "  count(keyword)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Poiskati želimo besede s pripono \"-in\" za samostalnike, ki označujejo ženska\n",
                "osebna imena (npr. Ärztin, Köchin, ...).\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "(konkordanca2 = kwic(woerter, pattern = c(\"*in\"), case_insensitive = FALSE) %>% \n",
                "  as_tibble()\n",
                ")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Žal vsebuje gornji seznam sobesedil veliko besednih oblik, ki niso ženska osebna\n",
                "imena (npr. ein, in, ...). Če želimo natančnejši seznam, moramo iskati na\n",
                "ustreznejši način, npr. z naborom nadomestnih znakov, tako imeovanih *regularnih\n",
                "izrazov* (regular expressions, \"regex\").\n",
                "\n",
                "Na portalu [**https://regex101.com/**](https://regex101.com/){.uri} lahko\n",
                "preizkušate in se učite regularnih izrazov.\n",
                "\n",
                "Poizvedovanje s pomočjo regularnih izrazov: \\*in.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "(konkordanca2 = kwic(woerter, pattern = \"\\\\A[A-Z][a-z]+[^Eae]in\\\\b\",\n",
                "                      valuetype = \"regex\", case_insensitive = FALSE) %>% \n",
                "  as_tibble() %>% \n",
                "  filter(keyword != \"Immerhin\", \n",
                "         keyword != \"Darin\",\n",
                "         keyword != \"Termin\",\n",
                "         keyword != \"Worin\",\n",
                "         keyword != \"Robin\",\n",
                "         keyword != \"Medizin\",\n",
                "         keyword != \"Austin\",\n",
                "         keyword != \"Musselin\",\n",
                "         keyword != \"Benjamin\",\n",
                "         keyword != \"Franklin\")\n",
                ")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Še drug primer uporabe regularnih izrazov Poizvedovanje s pomočjo regex:\n",
                "Manjšalnice / Diminutive (-chen, -lein). Katera manjšalna pripona prevladuje:\n",
                "-lein ali -chen ?\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "(konkordanca3a = kwic(woerter, \"*lein\",\n",
                "                      valuetype = \"glob\", case_insensitive = FALSE) %>% \n",
                "  as_tibble() %>% \n",
                "   count(keyword, sort = TRUE)\n",
                ")\n",
                "\n",
                "(konkordanca3b <- kwic(woerter, \"*chen\",\n",
                "                      valuetype = \"glob\", case_insensitive = FALSE) %>% \n",
                "  as_tibble() %>% \n",
                "   count(keyword, sort = T)\n",
                ")\n",
                "\n",
                "(konkordanca3 <- kwic(woerter, \n",
                "                      pattern = c(\"\\\\A[A-Z][a-z]*[^aäeiouürs]chen\\\\b\",\n",
                "                                  \"[A-Z]*[^kl]lein\\\\b\"),\n",
                "                      valuetype = \"regex\", case_insensitive = FALSE) %>% \n",
                "  as_tibble() %>% \n",
                "  filter(keyword != \"Welchen\", \n",
                "         keyword != \"Manchen\",\n",
                "         keyword != \"Solchen\",\n",
                "         keyword != \"Fräulein\")\n",
                ")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Poizvedovanje s pomočjo \"regex\": Frau + Priimek / Ime\n",
                "\n",
                "Obvezno nastavimo case_insensitive = FALSE, saj naj program razlikuje med\n",
                "velikimi in malimi začetnicami.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "(konkordanca4 <- kwic(woerter, pattern = phrase(\"\\\\bFrau\\\\b ^[A-Z][^[:punct:]]\"), \n",
                "                      valuetype = \"regex\", case_insensitive = FALSE) %>% \n",
                "  as_tibble()\n",
                ")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 6. Pogostnost\n",
                "\n",
                "Besedilno-besedna matrika (dfm) je izhodišče za izračun in grafični prikaz več\n",
                "statističnih količin, npr. tudi pogostnosti besednih oblik v posameznih\n",
                "besedilih:\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "matrika = dfm(besede, tolower = FALSE) # za zdaj obdržimo velike začetnice\n",
                "\n",
                "# Odstranimo besede, ki jih v vsebinski analizi ne potrebujemo (stopwords)\n",
                "matrika = dfm_select(matrika, selection = \"remove\", pattern = stoplist_de)\n",
                "matrika\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Program quanteda ima posebno funkcijo, ki sestavi seznam besednih oblik in\n",
                "njihove pogostnosti, tj. textstat_frequency().\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "library(quanteda.textstats)\n",
                "library(quanteda.textplots)\n",
                "\n",
                "(pogostnost = textstat_frequency(matrika, groups = c(\"prozess.txt\", \"tom.txt\"))\n",
                ")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Diagram najpogostnejših izrazov:\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "pogostnost %>% \n",
                "  slice_max(order_by = frequency, n = 20) %>% \n",
                "  mutate(feature = reorder_within(feature, frequency, frequency, sep = \": \")) %>%\n",
                "  # ggplot(aes(frequency, reorder(feature, frequency))) +\n",
                "  ggplot(aes(frequency, feature)) +\n",
                "  geom_col(fill=\"steelblue\") +\n",
                "  labs(x = \"Frequency\", y = \"\") +\n",
                "  facet_wrap(~ group, scales = \"free\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Po potrebi lahko seznam besednih pogostnosti oblik razdelimo na dva posebna\n",
                "seznama, in sicer s funkcijo filter().\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "(pogost_tom = textstat_frequency(matrika, groups = c(\"prozess.txt\", \"tom.txt\")) %>% \n",
                "  filter(group == \"tom.txt\")\n",
                ")\n",
                "\n",
                "(pogost_prozess = textstat_frequency(matrika, groups = c(\"prozess.txt\", \"tom.txt\")) %>% \n",
                "  filter(group == \"prozess.txt\")\n",
                ")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Glagoli rekanja in mišljenja: kateri so v izbranih besedilih pogostnejši?\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "(sagen = pogostnost %>%\n",
                "   filter(str_detect(feature, \"^(ge)?sag*\"))\n",
                ")\n",
                "\n",
                "(reden = pogostnost %>% \n",
                "    filter(str_detect(feature, \"^(ge)?rede*\"))\n",
                ")\n",
                "\n",
                "(fragen = pogostnost %>% \n",
                "    filter(str_detect(feature, \"^(ge)?frag*\"))\n",
                ")\n",
                "\n",
                "(antworten = pogostnost %>% \n",
                "    filter(str_detect(feature, \"^(ge)?antwort*\"))\n",
                ")\n",
                "\n",
                "(rufen = pogostnost %>% \n",
                "    filter(str_detect(feature, pattern = \"^(ge)?ruf*\", negate = FALSE)) %>% \n",
                "    filter(!str_detect(feature, \"ruh|run|rum|rui|ruch\"))\n",
                ")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "verb1 = sagen %>% \n",
                "  group_by(group) %>% \n",
                "  summarise(freq = sum(frequency)) %>% \n",
                "  mutate(verb = \"sagen\")\n",
                "\n",
                "verb2 = reden %>% \n",
                "  group_by(group) %>% \n",
                "  summarise(freq = sum(frequency)) %>% \n",
                "  mutate(verb = \"reden\")\n",
                "\n",
                "verb3 = fragen %>% \n",
                "  group_by(group) %>% \n",
                "  summarise(freq = sum(frequency)) %>% \n",
                "  mutate(verb = \"fragen\")\n",
                "\n",
                "verb4 = antworten %>% \n",
                "  group_by(group) %>% \n",
                "  summarise(freq = sum(frequency)) %>% \n",
                "  mutate(verb = \"antworten\")\n",
                "\n",
                "verb5 = rufen %>% \n",
                "  group_by(group) %>% \n",
                "  summarise(freq = sum(frequency)) %>% \n",
                "  mutate(verb = \"rufen\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Pet majhnih tabel lahko združimo v večjo tabelo, tj. s funkcijo rbind().\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "glagoli = rbind(verb1, verb2, verb3, verb4, verb5)\n",
                "glagoli\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Še diagram:\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "glagoli %>% \n",
                "  ggplot(aes(freq, verb, fill = verb)) +\n",
                "  geom_col() +\n",
                "  facet_wrap(~ group) +\n",
                "  theme(legend.position = \"none\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Tabelo lahko tudi prerazporedimo, npr. zaradi lažje primerjave besedil takole:\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "glagoli %>% \n",
                "  pivot_wider(id_cols = verb, names_from = group, values_from = freq)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 7. Kolokacije\n",
                "\n",
                "Koleksemi = slovarske enote, ki se sopojavljajo. Kolokacije = jezikovne prvine,\n",
                "ki se sopojavljajo.\n",
                "\n",
                "Statistična opredelitev: Če se dva izraza (npr. \"dober dan\") pojavljata bistveno\n",
                "pogosteje kot neposredna soseda, kakor bi naključno pričakovali, potem ju lahko\n",
                "obravnavamo kot kolokacijo.\n",
                "\n",
                "Jezikoslovna opredelitev: Kolokacija je pomensko povezano zaporedje besed.\n",
                "\n",
                "Funkcija textstat_collocations() v programu quanteda.\n",
                "\n",
                "\"woerter\" je seznam besednih oblik (padding = TRUE !), ki smo ga ustvarili\n",
                "zgoraj.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "(coll_2 = textstat_collocations(woerter, size = 2, tolower = TRUE) # naredi male črke !\n",
                ")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Kolokacije s tremi členi.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "(coll_3 = textstat_collocations(woerter, size = 3, tolower = FALSE)\n",
                ")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "(coll_4 = textstat_collocations(woerter, size = 4, tolower = FALSE)\n",
                ")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Sopomenski vprašalnici \"warum\" in \"wieso: s katerimi besednimi oblikami se\n",
                "sopojavljata?\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "(warum <- coll_2 %>% \n",
                "  filter(str_detect(collocation, \"^warum\"))\n",
                ")\n",
                "\n",
                "(wieso <- coll_2 %>% \n",
                "  filter(str_detect(collocation, \"^wieso\"))\n",
                ")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Kolokacija samostalniških izrazov. V nemščini imajo veliko začetnico. Najprej\n",
                "bomo sestavili seznam besednih oblik z veliko začetnico (woerter_caps). Potem\n",
                "lahko pridobimo seznam kolokacij (coll_caps2).\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "woerter_caps = tokens_select(woerter, pattern = \"^[A-Z]\", \n",
                "                                valuetype = \"regex\", \n",
                "                                case_insensitive = FALSE, \n",
                "                                padding = TRUE)\n",
                "\n",
                "coll_caps2 = textstat_collocations(woerter_caps, size = 2, tolower = FALSE, min_count = 5)\n",
                "head(coll_caps2, 100)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Ni smiselno upoštevati \"Der + samostalnik\" kot kolokacijo, saj se v nemščini\n",
                "velika večina samostalnikov pojavlja s členom.\n",
                "\n",
                "Zato bomo člene \"Der, Die, Das\" in še nekaj besednih oblik na začetku stavka\n",
                "spremenili v \"der, die , das\", ....\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "woerter_small = tokens_replace(woerter, \n",
                "                               pattern = c(\"Der\",\"Die\",\"Das\",\"Des\",\"Wollen\",\"Im\",\"Zum\",\n",
                "                                           \"Kein\",\"Jeden\",\"Wenn\",\"Als\",\"Da\",\"Aber\",\"Und\",\"Sehen\"), \n",
                "                               replacement = c(\"der\",\"die\",\"das\",\"des\",\"wollen\",\"im\",\"zum\",\n",
                "                                               \"kein\",\"jeden\",\"wenn\",\"als\",\"da\",\"aber\",\"und\",\"sehen\"))\n",
                "\n",
                "woerter_caps = tokens_select(woerter_small, pattern = \"^[A-Z]\", \n",
                "                                valuetype = \"regex\", \n",
                "                                case_insensitive = FALSE, \n",
                "                                padding = TRUE)\n",
                "\n",
                "coll_caps2 = textstat_collocations(woerter_caps, size = 2, tolower = FALSE, min_count = 5)\n",
                "head(coll_caps2, 100)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 8. Lematizacija\n",
                "\n",
                "Seznam slovarskih enot (lem) lahko naložimo z medmrežja na naš disk.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Preberi seznam slovarskih enot in pojavnic z diska\n",
                "lemdict = read.delim2(\"data/lemmatization_de.txt\", sep = \"\\t\", encoding = \"UTF-8\", \n",
                "                      col.names = c(\"lemma\", \"word\"), stringsAsFactors = F)\n",
                "\n",
                "# Pretvori podatkovna niza v znakovna niza\n",
                "lemma = as.character(lemdict$lemma) \n",
                "word = as.character(lemdict$word)\n",
                "\n",
                "# Lematiziraj pojavnice v naših besedilih\n",
                "lemmas <- tokens_replace(besede,\n",
                "                             pattern = word,\n",
                "                             replacement = lemma,\n",
                "                             case_insensitive = TRUE, \n",
                "                             valuetype = \"fixed\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Ustvarimo matriko s slovarskimi enotami (namesto pojavnic).\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "matrika_lem = dfm(lemmas, tolower = FALSE) # za zdaj obdržimo velike začetnice\n",
                "\n",
                "# Odstranimo besede, ki jih v vsebinski analizi ne potrebujemo (stopwords)\n",
                "matrika_lem = dfm_select(matrika_lem, selection = \"remove\", pattern = stoplist_de)\n",
                "matrika_lem\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 9. Besedni oblaček\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "textplot_wordcloud(matrika_lem, comparison = TRUE, adjust = 0.3, color = c(\"darkblue\",\"darkgreen\"),\n",
                "                   max_size = 4, min_size = 0.75, rotation = 0.5, min_count = 30, max_words = 250)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Lepši oblaček (za obe besedili skupaj).\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# install.packages(\"wordcloud2)\n",
                "matrika_lem_prozess = matrika_lem[1,]\n",
                "\n",
                "set.seed(1320)\n",
                "library(wordcloud2)\n",
                "topfeat <- as.data.frame(topfeatures(matrika_lem_prozess, 100))\n",
                "topfeat <- rownames_to_column(topfeat, var = \"word\")\n",
                "wordcloud2(topfeat)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "matrika_lem_tom = matrika_lem[2,]\n",
                "\n",
                "set.seed(1320)\n",
                "library(wordcloud2)\n",
                "topfeat <- as.data.frame(topfeatures(matrika_lem_tom, 100))\n",
                "topfeat <- rownames_to_column(topfeat, var = \"word\")\n",
                "wordcloud2(topfeat)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 10. Položaj v besedilu (xray)\n",
                "\n",
                "Diagram prikazuje, kje v besedilih se pojavlja besedna oblika \"frau\". Podobno:\n",
                "Voyant Tools (MicroSearch).\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "kwic_frau = kwic(lemmas, pattern = \"frau\")\n",
                "textplot_xray(kwic_frau)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 11. Slovarska raznolikost\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "textstat_lexdiv(matrika, measure = \"all\")\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 12. Podobnost besedil\n",
                "\n",
                "Ta postopek je bolj zanimiv, če želimo primerjati več besedil. Zato bomo dodali\n",
                "še Kafkino novelo.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# odpremo datoteko\n",
                "verwandl = readtext(\"data/books/verwandlung/verwandlung.txt\", encoding = \"UTF-8\")\n",
                "# ustvarimo nov korpus\n",
                "verw_corp = corpus(verwandl)\n",
                "# združimo novi korpus s prrejšnjim\n",
                "romane3 = romane + verw_corp\n",
                "# tokenizacija\n",
                "romane3_toks = tokens(romane3)\n",
                "# ustvarimo matriko (dfm)\n",
                "romane3_dfm = dfm(romane3_toks)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Rezultat: Kafkina novela \"Die Verwandlung\" je Kafkinemu romanu \"Der Prozess\"\n",
                "nekoliko podobnejša kot Twainov roman \"Tom Sawyer\".\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "textstat_simil(romane3_dfm, method = \"cosine\", margin = \"documents\")\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Podobnost oblik (features).\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# compute some term similarities\n",
                "simil1 = textstat_simil(matrika, matrika[, c(\"Josef\", \"Tom\", \"Sawyer\", \"Huck\", \"Finn\")], \n",
                "                         method = \"cosine\", margin = \"features\")\n",
                "head(as.matrix(simil1), 10)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Različnost besedil (Kaj je ta metoda upoštevala? Razliko v dolžini?):\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# plot a dendrogram after converting the object into distances\n",
                "dist1 = textstat_dist(romane3_dfm, method = \"euclidean\", margin = \"documents\")\n",
                "plot(hclust(as.dist(dist1)))\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 13. Ključne besede\n",
                "\n",
                "Katere besedne oblike lahko uvrstimo med ključne besede, tj. take izraze, ki so\n",
                "najbolj značilni za neko besedilo? Program quanteda ima funkcijo\n",
                "*textstat_keyness()*: ciljno besedilo (target) primerjamo z referenčnim\n",
                "besedilom (reference).\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "key_tom <- textstat_keyness(matrika, target = \"tom.txt\")\n",
                "key_tom\n",
                "\n",
                "key_prozess <- textstat_keyness(matrika, target = \"prozess.txt\")\n",
                "key_prozess\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "textplot_keyness(key_tom, key_tom$n_target == 1)\n",
                "textplot_keyness(key_tom, key_prozess$n_target == 1)\n",
                "textplot_keyness(key_tom)\n",
                "textplot_keyness(key_prozess)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 14. Razumljivost besedil\n",
                "\n",
                "Indeksi razumljivosti (readability index) so prirejeni za angleščino, za druge\n",
                "jezike veljajo v manjši meri.\n",
                "\n",
                "Flesch-Indeks: Prozess ima nekoliko nižjo vrednost (52) kot Tom Sawyer (61), kar\n",
                "pomeni, da Prozess (zaradi daljših povedi in besed) težje beremo (razumemo), Tom\n",
                "Sawyer pa z večjo lahkoto.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "textstat_readability(romane, measure = c(\"Flesch\", \"Flesch.Kincaid\", \"FOG\", \"FOG.PSK\", \"FOG.NRI\"))\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 15. Omrežje sopojavitev (FCM)\n",
                "\n",
                "Matriko sopojavljanja besednih oblik (FCM) pridobimo v dveh korakih: - najprej\n",
                "izberemo seznam izrazov (pattern) iz matrike (dfm), - potem določimo matriko\n",
                "sopojavljanja besednih oblik (fcm).\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "dfm_tags <- dfm_select(matrika[2,], pattern = (c(\"tom\", \"huck\", \"*joe\", \"becky\", \"tante\", \"witwe\",\n",
                "                                                 \"polly\", \"sid\", \"mary\", \"thatcher\", \"höhle\", \"herz\",\n",
                "                                                 \"*schule\", \"katze\", \"geld\", \"zaun\", \"piraten\",\n",
                "                                                 \"schatz\")))\n",
                "toptag <- names(topfeatures(dfm_tags, 50))\n",
                "head(toptag)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Construct feature-cooccurrence matrix (fcm) of tags\n",
                "fcm_tom <- fcm(matrika[2,]) # besedilo 2 je tom.txt\n",
                "head(fcm_tom)\n",
                "top_fcm <- fcm_select(fcm_tom, pattern = toptag)\n",
                "textplot_network(top_fcm, min_freq = 0.6, edge_alpha = 0.8, edge_size = 5)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 16. Slovnična analiza\n",
                "\n",
                "Za slovnično analizo in lematizacijo besednih oblik lahko uporabljamo posebne\n",
                "programe (npr. spacyr ali udpipe).\n",
                "\n",
                "Program udpipe je na voljo za številne jezike, tudi za nemščino in slovenščino.\n",
                "\n",
                "## 16.1 Priprava\n",
                "\n",
                "Pred prvo uporabo moramo naložiti model za nemški jezik z interneta.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "library(udpipe)\n",
                "sprachmodell <- udpipe_download_model(language = \"german\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "V naslednjem koraku naložimo jezikovni model v pomnilnik.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "udmodel_de <- udpipe_load_model(sprachmodell$file_model)\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Če je jezikovni model že v naši delovni mapi, download ni potreben, saj ga lahko\n",
                "takoj naložimo z diska v pomnilnik.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "file_model = \"german-gsd-ud-2.5-191206.udpipe\"\n",
                "udmodel_de <- udpipe_load_model(file_model)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Naslednji korak je *udpipe_annotate()*: program udpipe označuje besedne oblike\n",
                "po več merilih.\n",
                "\n",
                "Udpipe prebere in označuje besedilo takole:\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Na začetku je readtext prebral besedila, shranili smo jih v spremenljivki \"txt\".\n",
                "x <- udpipe_annotate(udmodel_de, x = txt$text, trace = TRUE)\n",
                "\n",
                "# # samo prvo besedilo:\n",
                "# x <- udpipe_annotate(udmodel_de, x = txt$text[1], trace = TRUE)\n",
                "\n",
                "x <- as.data.frame(x)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Zgradba podatkovnega niza (structure of data frame):\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "str(x)\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Podatkovni niz ima tako obliko:\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "x\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 16.2 Primerjava Noun : Pron\n",
                "\n",
                "Zdaj lahko začnemo poizvedovati po besednih oblikah, slovarskih enotah in\n",
                "slovničnih kategorijah.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "(tabela = x %>% \n",
                "  group_by(doc_id) %>% \n",
                "  count(upos) %>% \n",
                "  filter(!is.na(upos),\n",
                "         upos != \"PUNCT\")\n",
                ")\n",
                "\n",
                "tabela %>% \n",
                "  mutate(upos = reorder_within(upos, n, n, sep = \": \")) %>% \n",
                "  ggplot(aes(n, upos, fill = upos)) +\n",
                "  geom_col() +\n",
                "  facet_wrap(~ doc_id, scales = \"free\") +\n",
                "  theme(legend.position = \"none\") +\n",
                "  labs(x = \"Število pojavnic\", y = \"\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Izračun deležev v odstotkih:\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "(delezi = tabela %>% \n",
                "  mutate(prozent = n/sum(n)) %>% \n",
                "  pivot_wider(id_cols = upos, names_from = doc_id, values_from = n:prozent)\n",
                ")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "delezi %>% \n",
                "  filter(upos %in% c(\"NOUN\", \"PRON\"))\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Ali se besedili razlikujeta glede na razmerje med samostalniki in zaimki?\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# za hi kvadrat test potrebujemo le drugi in tretji stolpec\n",
                "nominal = delezi %>% \n",
                "  filter(upos %in% c(\"NOUN\", \"PRON\")) %>% \n",
                "  select(n_doc1, n_doc2) \n",
                "\n",
                "chisq.test(nominal)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Besedili se razlikujeta glede razmerja med samostalniki in zaimki: X\\^2 (1) =\n",
                "147,38; p \\< 0,001. Iz gornje tabele pogostnosti je razvidno, da je delež\n",
                "zaimkov v romanu \"Prozess\" sorazmerno večji kot v romanu \"Tom Sawyer\". Da bi\n",
                "ugotovili, kaj to pomeni, bi si morali podrobneje ogledati, kateri zaimki in\n",
                "kateri samostalniki bistveno vplivajo na to številčno razmerje. Na splošno\n",
                "velja, da so zaimki manj zanesljiva jezikovna sredstva kot samostalniki,\n",
                "samostalniki pa so bolj zapleteni.\n",
                "\n",
                "Če želimo primerjati eno besedno vrsto z vsemi drugimi v podatkovnem nizu, je\n",
                "pretvorba bolj zapletena, saj moramo podobno kot v Excelu - najprej izračunati\n",
                "vsoto za vse besedne vrste, - potem odšteti število zaimkov oz. samostalnikov od\n",
                "vsote, - razliko pa upoštevati za tabelo 2x2 za hi kvadrat test.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "(zaimki = x %>% \n",
                "  group_by(doc_id) %>% \n",
                "  count(upos) %>% \n",
                "  filter(!is.na(upos),\n",
                "         upos != \"PUNCT\") %>% \n",
                "  mutate(vsota = sum(n),\n",
                "         no_noun = vsota - n[upos == \"NOUN\"],\n",
                "         no_pron = vsota - n[upos == \"PRON\"]) %>% \n",
                "  filter(upos == \"PRON\") %>% \n",
                "  select(doc_id, n, no_pron) %>% \n",
                "  pivot_longer(-doc_id, 'kategorija', 'vrednost') %>%\n",
                "  pivot_wider(kategorija, doc_id)\n",
                ")\n",
                "\n",
                "(samostalniki = x %>% \n",
                "  group_by(doc_id) %>% \n",
                "  count(upos) %>% \n",
                "  filter(!is.na(upos),\n",
                "         upos != \"PUNCT\") %>% \n",
                "  mutate(vsota = sum(n),\n",
                "         no_noun = vsota - n[upos == \"NOUN\"],\n",
                "         no_pron = vsota - n[upos == \"PRON\"]) %>% \n",
                "  filter(upos == \"NOUN\") %>% \n",
                "  select(doc_id, n, no_noun) %>% \n",
                "  pivot_longer(-doc_id, 'kategorija', 'vrednost') %>%\n",
                "  pivot_wider(kategorija, doc_id)\n",
                ")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Hi kvadrat testa: - primerjava števila zaimkov nasproti ostalim besednim vrstam,\n",
                "- primerjava števila samostalnikov nasproti ostalim besednim vrstam.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# izločimo prvi stolpec [, -1], za hi kvadrat test potrebujemo le drugi in tretji stolpec\n",
                "chisq.test(zaimki[,-1])\n",
                "chisq.test(samostalniki[,-1])\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Besedili se razlikujeta glede deleža zaimkov in samostalnikov.\n",
                "\n",
                "## 16.3 Primerjava veznikov\n",
                "\n",
                "Primerjati želimo število stavkov s prirednim in podrednim veznikom.\n",
                "\n",
                "Osnovna domneva je, da priredno zložene povedi (vsebujejo stavek, uveden s\n",
                "prirednim veznikom) lažje razumemo kot podredno zložene povedi (vsebujejo\n",
                "stavek, uveden s podrednim veznikom).\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "(vezniki = tabela %>% \n",
                "  filter(upos %in% c(\"CCONJ\", \"SCONJ\")) %>% \n",
                "  mutate(prozent = n/sum(n)) %>% \n",
                "  pivot_wider(id_cols = upos, names_from = doc_id, values_from = n:prozent)\n",
                ")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Odstotki nakazujejo, da je v romanu Prozess delež prirednih veznikov manjši kot\n",
                "v romanu Tom Sawyer.\n",
                "\n",
                "Hi kvadrat test (upoštevane so le povedi, ki vsebujejo veznik) za preverjanje,\n",
                "ali je razlika dovolj velika, da bi bila nenaključna.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "chisq.test(vezniki[,c(2:3)])\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Razlika med romanoma je statistično značilna.\n",
                "\n",
                "Če upoštevamo tudi vsote drugih besednih vrst (kot zgoraj):\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "(koord = tabela %>% \n",
                "  mutate(vsota = sum(n),\n",
                "         no_cconj = vsota - n[upos == \"CCONJ\"],\n",
                "         no_sconj = vsota - n[upos == \"SCONJ\"]) %>% \n",
                "  filter(upos == \"CCONJ\") %>% \n",
                "  select(doc_id, n, no_cconj) %>% \n",
                "  pivot_longer(-doc_id, 'kategorija', 'vrednost') %>%\n",
                "  pivot_wider(kategorija, doc_id)\n",
                ")\n",
                "\n",
                "(subord = tabela %>% \n",
                "  mutate(vsota = sum(n),\n",
                "         no_cconj = vsota - n[upos == \"CCONJ\"],\n",
                "         no_sconj = vsota - n[upos == \"SCONJ\"]) %>% \n",
                "  filter(upos == \"SCONJ\") %>% \n",
                "  select(doc_id, n, no_sconj) %>% \n",
                "  pivot_longer(-doc_id, 'kategorija', 'vrednost') %>%\n",
                "  pivot_wider(kategorija, doc_id)\n",
                ")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Hi kvadrat preizkus izkazuje razliko med romanoma\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "chisq.test(koord[,-1])\n",
                "chisq.test(subord[,-1])\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Besedili se razlikujeta glede števila veznikov.\n",
                "\n",
                "## 16.4 Slovarske enote\n",
                "\n",
                "Program udpipe je vsako besedno obliko dodelil slovarski enoti (lemma). Koliko\n",
                "koliko slovarskih enot je v besedilih? Katerim besednim vrstam najpogosteje\n",
                "pripadajo?\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "(tabela2 = x %>% \n",
                "  group_by(doc_id, upos) %>% \n",
                "    filter(!is.na(upos),\n",
                "           upos != \"PUNCT\",\n",
                "           upos != \"X\") %>% \n",
                "  distinct(lemma) %>% \n",
                "  count(lemma) %>% \n",
                "  summarise(lemmas = sum(n)) %>% \n",
                "  mutate(prozent = round(lemmas/sum(lemmas), 4)) %>% \n",
                "  arrange(-prozent)\n",
                ")\n",
                "\n",
                "tabela2 %>% \n",
                "  # slice_max(order_by = prozent, n=6) %>% \n",
                "  mutate(upos = reorder_within(upos, lemmas, paste(\"(\",100*prozent,\"%)\"), sep = \" \")) %>%\n",
                "  ggplot(aes(prozent, upos, fill = upos)) +\n",
                "  geom_col() +\n",
                "  facet_wrap(~ doc_id, scales = \"free\") +\n",
                "  theme(legend.position = \"none\") +\n",
                "  scale_x_continuous(labels = percent_format()) +\n",
                "  labs(x = \"Anteil\", y = \"Wortklasse\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 16.5 Korelacija besed\n",
                "\n",
                "Katere besedne pogostnosti se vzporedno povečujejo ali zmanjšujejo (pairwise\n",
                "correlation) ? Podobno analizno orodje: Voyant Tools.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "library(widyr)\n",
                "\n",
                "# pairwise correlation\n",
                "(correlations = x %>% \n",
                "  filter(dep_rel != \"punct\", dep_rel != \"nummod\") %>%\n",
                "  mutate(lemma = tolower(lemma), token = tolower(token),\n",
                "         lemma = str_trim(lemma), token = str_trim(token)) %>% \n",
                "  janitor::clean_names() %>%\n",
                "  group_by(doc_id, lemma, token, sentence_id) %>% \n",
                "  # add_count(token) %>% \n",
                "  summarize(Freq = n()) %>% \n",
                "  arrange(-Freq) %>% \n",
                "  filter(Freq > 2) %>% \n",
                "  pairwise_cor(lemma, sentence_id, sort = TRUE) %>% \n",
                "  filter(correlation < 1 & correlation > 0.3)\n",
                ")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Tom Sawyer: Zaun.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "correlations %>%\n",
                "  filter(item1 == \"zaun\") %>%\n",
                "  mutate(item2 = fct_reorder(item2, correlation)) %>%\n",
                "  ggplot(aes(item2, correlation, fill = item2)) +\n",
                "  geom_col(show.legend = F) +\n",
                "  coord_flip() +\n",
                "  labs(title = \"What tends to appear with 'Zaun'?\",\n",
                "       subtitle = \"Among elements that appeared in at least 2 sentences\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Prozess: Gericht.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "correlations %>%\n",
                "  filter(item1 == \"gericht\") %>%\n",
                "  mutate(item2 = fct_reorder(item2, correlation)) %>%\n",
                "  ggplot(aes(item2, correlation, fill = item2)) +\n",
                "  geom_col(show.legend = F) +\n",
                "  coord_flip() +\n",
                "  labs(title = \"What tends to appear with 'Gericht'?\",\n",
                "       subtitle = \"Among elements that appeared in at least 2 sentences\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 17. Sentiment\n",
                "\n",
                "Stopnjo čustvenosti ali emocionalnosti besedila je mogoče določiti s\n",
                "sentimentnim slovarjem.\n",
                "\n",
                "## 17.1 Različica 1\n",
                "\n",
                "Uporaba nrc leksikona za nemščino (priložen programu syuzhet).\n",
                "\n",
                "Najprej besedilo s funkcijo *get_sentences()* razcepimo na povedi.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "library(syuzhet)\n",
                "\n",
                "tom_v = get_sentences(txt$text[2]) # izberemo drugo besedilo: tom.txt\n",
                "tom_v = (tom_v[-1]) # tako lahko izločimo prvo vrstico (uredniško pripombo)\n",
                "head(tom_v[-1])\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Funkcija *get_sentiment()* dodeli besedam v povedih pozitivno (+1), negativno\n",
                "(-1) ali nevtralno (0) čustveno vrednost. Program te vrednosti sešteje.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "tom_values <- get_sentiment(tom_v, method = \"nrc\", language = \"german\")\n",
                "length(tom_values)\n",
                "tom_values[100:110]\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Povedi, čustvene vrednosti in dolžino povedi povežemo v podatkovni niz. To nam\n",
                "olajšuje oceno, kako uspešna je bila uporaba sentimentnega slovarja v našem\n",
                "besedilu. Preimenovali bomo tudi nekaj stolpcev.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "sentiment1 = cbind(tom_v, tom_values, ntoken(tom_v)) %>% \n",
                "  as.data.frame() %>% \n",
                "  rename(words = V3,\n",
                "         text = tom_v,\n",
                "         values = tom_values) %>% \n",
                "  mutate(doc_id = \"tom.txt\") %>% \n",
                "  rowid_to_column(var = \"sentence\")\n",
                "head(sentiment1)\n",
                "View(sentiment1)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Gornje postopke ponovimo za besedilo, ki ga želimo primerjati s prvim.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "prozess_v = get_sentences(txt$text[1]) # izberemo prvo besedilo: prozess.txt\n",
                "prozess_v = (prozess_v[-1]) # tako lahko izločimo prvo vrstico (uredniško pripombo)\n",
                "prozess_values <- get_sentiment(prozess_v, method = \"nrc\", language = \"german\")\n",
                "sentiment2 = cbind(prozess_v, prozess_values, ntoken(prozess_v)) %>% \n",
                "  as.data.frame() %>% \n",
                "  rename(words = V3,\n",
                "         text = prozess_v,\n",
                "         values = prozess_values) %>% \n",
                "  mutate(doc_id = \"prozess.txt\") %>% \n",
                "  rowid_to_column(var = \"sentence\")\n",
                "head(sentiment2)\n",
                "View(sentiment2)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "S seštevanjem čustvenih vrednosti je mogoče oceniti, katero besedilo ima več\n",
                "pozitivno ocenjenih besed. V ta namen bomo združili podatkovna niza in uredili\n",
                "obliko stolpcev \"words\" in \"values\".\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "sentiment = rbind(sentiment1, sentiment2) %>% as_tibble() %>% \n",
                "  mutate(values = parse_number(values),\n",
                "         words = parse_number(words)) %>%\n",
                "  select(doc_id, sentence, words, values, text)\n",
                "head(sentiment)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Rezultat: po gornji metodi je povprečje čustvenih vrednosti v romanu \"Prozess\"\n",
                "nekoliko večje kot v romanu \"Tom Sawyer\". To je v nasprotju z našim\n",
                "pričakovanjem, saj Tom Sawyer vsebuje kar nekaj vedrih zgodb, je pa res, da so\n",
                "njegove pustolovščine pogosto tudi nevarne ali strašljive.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "sentiment %>% \n",
                "  group_by(doc_id) %>% \n",
                "  summarise(polarnost = mean(values))\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Poskusimo drugače: pozitivne, nevtralne in negativne vrednosti obravnajmo ločeno\n",
                "in upoštevajmo tudi dolžino povedi.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "sentiment1 = sentiment %>% \n",
                "  group_by(doc_id) %>% \n",
                "  mutate(positive = ifelse(values > 0, abs(values), 0),\n",
                "         neutral = ifelse(values == 0, 1, 0),\n",
                "         negative = ifelse(values < 0, abs(values), 0))\n",
                "sentiment1 %>% \n",
                "  summarise(pos = mean(100*positive/words),\n",
                "            neut = mean(100*neutral/words),\n",
                "            neg = mean(100*negative/words))\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Ta rezultat je skladnejši z našim pričakovanjem.\n",
                "\n",
                "Poglejmo še nekaj povedi, ki so bile ocenjene negativno:\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "sentiment1 %>% \n",
                "  filter(negative > 0)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 17.2 Različica 2\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "tom_v = get_sentences(txt$text[2])\n",
                "tom_nrc_values = get_nrc_sentiment(tom_v)\n",
                "tom_joy_items = which(tom_nrc_values$joy > 0)\n",
                "head(tom_v[tom_joy_items], 4)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "nrc_sentiment = as.data.frame(cbind(tom_v, tom_nrc_values))\n",
                "head(nrc_sentiment)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 17.3 Različica 3\n",
                "\n",
                "Drugi sentimentni slovarji z medmrežja: npr. BAWLR lahko uporabljamo kot\n",
                "sentimentni slovar.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# This lexicons contains values of Emotional valence and arousal ranging from 1 to 5.\n",
                "# But this extended version contains also binary Emo_Val values (1, -1).\n",
                "bawlr <- read.delim2(\"data/BAWLR_utf8.txt\", sep = \"\\t\", dec = \",\", fileEncoding = \"UTF-8\", \n",
                "                     header = T, stringsAsFactors = T)\n",
                "# # bawlr$EmoVal <- as.character(bawlr$EmoVal)\n",
                "# # str(EmoVal)\n",
                "# bawlr$EmoVal <- gsub('NEG', '-1', bawlr$EmoVal)\n",
                "# bawlr$EmoVal <- gsub('POS', '1', bawlr$EmoVal)\n",
                "# bawlr$EmoVal <- as.numeric(bawlr$EmoVal)\n",
                "head(bawlr)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Sestavimo dva seznama:\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "positive.words = bawlr %>% \n",
                "  mutate(WORD_LOWER = as.character(WORD_LOWER)) %>% \n",
                "  select(EmoVal, WORD_LOWER) %>% \n",
                "  filter(EmoVal == \"POS\") %>% \n",
                "  select(WORD_LOWER) %>% \n",
                "  filter(str_detect(WORD_LOWER, \"[a-zA-Z]\"))\n",
                "\n",
                "negative.words = bawlr %>% \n",
                "  mutate(WORD_LOWER = as.character(WORD_LOWER)) %>% \n",
                "  select(EmoVal, WORD_LOWER) %>% \n",
                "  filter(EmoVal == \"NEG\") %>% \n",
                "  select(WORD_LOWER) %>% \n",
                "  filter(str_detect(WORD_LOWER, \"[a-zA-Z]\"))\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Ustvarimo quanteda slovar *dictionary()*:\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "bawlr_dict = dictionary(list(positive = list(positive.words), negative = list(negative.words)))\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Uporabljamo matriko (dfm) s slovarskimi enotami (lemma), saj slovar bawlr_dict\n",
                "vsebujejo le osnovno obliko slovarskih enot.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "matrika_lemmas = dfm(matrika_lem, tolower = TRUE)\n",
                "\n",
                "result = matrika_lemmas %>% \n",
                "  dfm_lookup(bawlr_dict) %>% \n",
                "  convert(to = \"data.frame\") %>% \n",
                "  as_tibble\n",
                "result\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Dodamo lahko skupno dolžino besed, če želimo normalizirati rezultat z ozirom na\n",
                "dolžino besedil.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "result = result %>% mutate(length=ntoken(matrika_lemmas))\n",
                "result\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Po navadi želimo izračunati skupni sentimentno vrednost. Možnosti je več: npr. -\n",
                "odšteti negativne vrednosti od pozitivnih in nato razliko deliti z vsoto obeh\n",
                "vrednosti, - odšteti negativne vrednosti od pozitivnih in nato razliko deliti z\n",
                "dolžino besedil,\n",
                "\n",
                "Izračunamo lahko tudi stopnjo subjektivnosti, tj. koliko čustvenih vrednosti je\n",
                "skupno izraženih:\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "result = result %>% mutate(sentiment1=(positive - negative) / (positive + negative))\n",
                "result = result %>% mutate(sentiment2=(positive - negative) / length)\n",
                "result = result %>% mutate(subjektivnost=(positive + negative) / length)\n",
                "result\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Barvno označevanje\n",
                "\n",
                "Program corpustools barvno označuje besede v besedilih z ozirom na čustvene\n",
                "vrednosti besed v sentimentnem slovarju.\n",
                "\n",
                "Prvi korak je ustvarjanje tcorpusa.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "library(corpustools)\n",
                "t = create_tcorpus(txt, doc_column=\"doc_id\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "V drugem koraku sledi iskanje po slovarju (tcorpus):\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "t$code_dictionary(bawlr_dict, column = 'bawlr')\n",
                "t$set('sentiment', 1, subset = bawlr %in% c('positive','neg_negative'))\n",
                "t$set('sentiment', -1, subset = bawlr %in% c('negative','neg_positive'))\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Prikaz barvno označenih besedil v oknu \"Viewer\":\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "browse_texts(t, scale='sentiment')\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Prikaz barvno označenih besedil v spletnem brskalniku in shranjevanje v obliki\n",
                "html datoteke:\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "browse_texts(t, scale='sentiment', filename = \"sentiment_prozess_tom.html\", \n",
                "             header = \"Sentiment in Kafkas Prozess und Twains Tom Sawyer\")\n"
            ]
        }
    ],
    "metadata": {
        "anaconda-cloud": "",
        "kernelspec": {
            "display_name": "R",
            "langauge": "R",
            "name": "ir"
        },
        "language_info": {
            "codemirror_mode": "r",
            "file_extension": ".r",
            "mimetype": "text/x-r-source",
            "name": "R",
            "pygments_lexer": "r",
            "version": "3.4.1"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}
